<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="last-modified" content="2020-04-30 20:15:11 +0800">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- meta "search-domain" used for google site search function google_search() -->
    <meta name="search-domain" value="">
    <link rel="stylesheet" type="text/css" href="../assets/css/bootstrap.css" />
    <link rel="stylesheet" type="text/css" href="../assets/css/bootstrap-theme.css" />
    <link rel="stylesheet" type="text/css" href="../assets/css/lesson.css" />
    <link rel="stylesheet" type="text/css" href="../assets/css/syntax.css" />
    
    <link rel="shortcut icon" type="image/x-icon" href="/favicon-swc.ico" />
    
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
	<script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
	<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
	<![endif]-->
    <title>Exploring Differences Between Directive-Based GPU Programming Models: Multi-GPU implementation</title>
  </head>
  <body>
    <div class="container">
      
<nav class="navbar navbar-default">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

      
      

      
      <a class="navbar-brand" href="../index.html">Home</a>

    </div>
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav">

	
        <li><a href="../conduct/">Code of Conduct</a></li>

        
	
        <li><a href="../setup.html">Setup</a></li>

        
        <li class="dropdown">
          <a href="../" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Episodes <span class="caret"></span></a>
          <ul class="dropdown-menu">
            
            <li><a href="../01-talks/index.html">Talks</a></li>
            
            <li><a href="../02-laplace-introduction/index.html">Introduction to Laplace Equation</a></li>
            
            <li><a href="../03-serial-implementation/index.html">Serial Implementation</a></li>
            
            <li><a href="../04-profiling/index.html">Profiling</a></li>
            
            <li><a href="../05-loop-parallelisation/index.html">Loop parallelisation</a></li>
            
            <li><a href="../06-data-management/index.html">Data management</a></li>
            
            <li><a href="../07-multi-gpu/index.html">Multi-GPU implementation</a></li>
            
<!--	    <li role="separator" class="divider"></li>
            <li><a href="../aio.html">All in one page (Beta)</a></li>
-->
          </ul>
        </li>
	
<!--
	
	
        <li class="dropdown">
          <a href="../" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Extras <span class="caret"></span></a>
          <ul class="dropdown-menu">
            <li><a href="../reference.html">Reference</a></li>
            
            <li><a href="../about/index.html">About</a></li>
            
            <li><a href="../discuss/index.html">Discussion</a></li>
            
            <li><a href="../figures/index.html">Figures</a></li>
            
            <li><a href="../guide/index.html">Instructor Notes</a></li>
            
          </ul>
        </li>
	
-->

	
        <li><a href="../LICENSE.html">License</a></li>
<!--	
	<li><a href="/edit/gh-pages/_episodes/07-multi-gpu.md">Improve this page <span class="glyphicon glyphicon-pencil" aria-hidden="true"></span></a></li>
	
--> 
      </ul>
      <form class="navbar-form navbar-right" role="search" id="search" onsubmit="google_search(); return false;">
        <div class="form-group">
          <input type="text" id="google-search" placeholder="Search..." aria-label="Google site search">
        </div>
      </form>
    </div>
  </div>
</nav>


<div class="row">
  <div class="col-xs-1">
    <h3 class="text-left">
      
      <a href="../06-data-management/index.html"><span class="glyphicon glyphicon-menu-left" aria-hidden="true"></span><span class="sr-only">previous episode</span></a>
      
    </h3>
  </div>
  <div class="col-xs-10">
    
    <h3 class="maintitle"><a href="../">Exploring Differences Between Directive-Based GPU Programming Models</a></h3>
    
  </div>
  <div class="col-xs-1">
    <h3 class="text-right">
      
      <a href="../"><span class="glyphicon glyphicon-menu-up" aria-hidden="true"></span><span class="sr-only">lesson home</span></a>
      
    </h3>
  </div>
</div>

<article>
<div class="row">
  <div class="col-md-1">
  </div>
  <div class="col-md-10">
    <h1 class="maintitle">Multi-GPU implementation</h1>
  </div>
  <div class="col-md-1">
  </div>
</div>


<blockquote class="objectives">
  <h2>Overview</h2>

  <div class="row">
    <div class="col-md-3">
      <strong>Teaching:</strong> 45 min
      <br/>
      <strong>Exercises:</strong> 30 min
    </div>
    <div class="col-md-9">
      <strong>Questions</strong>
      <ul>
	
	<li><p>Extra: implementing multi-GPU parallelisation</p>
</li>
	
      </ul>
    </div>
  </div>

  <div class="row">
    <div class="col-md-3">
    </div>
    <div class="col-md-9">
      <strong>Objectives</strong>
      <ul>
	
	<li><p>Use OpenMP to create mutliple CPU threads</p>
</li>
	
	<li><p>Use OpenACC and OpenMP API functions to assign threads to devices</p>
</li>
	
	<li><p>Use update directives to synchronise halo-exchange boundaries</p>
</li>
	
      </ul>
    </div>
  </div>

</blockquote>

<h1 id="mutli-gpu-implementation">Mutli-GPU implementation</h1>

<blockquote class="callout">
  <h2 id="where-to-start">Where to start?</h2>
  <p>This episode starts in <em>5_single-gpu/</em> directory. Decide if you want to work on OpenACC, OpenMP or both and follow the instructions below.</p>
</blockquote>

<h2 id="strategies">Strategies</h2>
<p>GPU-accelerated HPC systems are usually based on multi-GPU nodes. This means that in order to take advantage of the full computational power of the node we need to parallelise our application across multiple GPUs within the node. There are at least two strategies to achieve this:</p>
<ul>
  <li>use MPI to create multiple processes and assign processes to GPUs,</li>
  <li>use multithreading programming model (e.g. OpenMP) and assign threads to GPUs.</li>
</ul>

<p>In this episode we will use OpenMP to generate multiple threads and assign threads to GPUs. Each of the threads will be assigned to its unique GPU.</p>

<p>The computational nature of the Laplace equation solver will require synchronisation on the boundaries of domains assigned to various GPUs.</p>

<h2 id="multithreading-and-thread-gpu-affinity">Multithreading and thread-GPU affinity</h2>

<p>We will start by creating OpenMP parallel region around the <em>while</em> loop. We will set the default data type to be <em>shared</em>.</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#pragma omp parallel default(shared) firstprivate(...)
</span><span class="p">{</span>
  <span class="p">...</span>
  <span class="k">while</span> <span class="p">(</span> <span class="n">dt</span> <span class="o">&gt;</span> <span class="n">MAX_TEMP_ERROR</span> <span class="o">&amp;&amp;</span> <span class="n">iteration</span> <span class="o">&lt;=</span> <span class="n">max_iterations</span> <span class="p">)</span> <span class="p">{</span>
  <span class="p">...</span>
<span class="p">}</span>
</code></pre></div></div>
<p>Now that we have created multiple threads, we will create affinity between threads and GPUs. For this we will use OpenMP and OpenACC API query functions.</p>

<p>For this to work we must first include appropriate header files:</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include &lt;openacc.h&gt;
#include &lt;omp.h&gt;
</span></code></pre></div></div>

<p>First, we will query for the number of available threads and set a thread ID.</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">num_threads</span> <span class="o">=</span> <span class="n">omp_get_num_threads</span><span class="p">();</span>
  <span class="n">thread_id</span>  <span class="o">=</span> <span class="n">omp_get_thread_num</span><span class="p">();</span>
</code></pre></div></div>

<p>Next, we will query for the number of devices and compute the GPU device ID for each thread by taking thread ID module number of available GPU devices.</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">num_devices</span> <span class="o">=</span> <span class="n">acc_get_num_devices</span><span class="p">(</span><span class="n">acc_device_nvidia</span><span class="p">);</span>
  <span class="n">device_id</span>  <span class="o">=</span> <span class="n">thread_id</span> <span class="o">%</span> <span class="n">num_devices</span><span class="p">;</span>
  <span class="n">acc_set_device_num</span><span class="p">(</span><span class="n">device_id</span><span class="p">,</span> <span class="n">acc_device_nvidia</span><span class="p">);</span>
</code></pre></div></div>

<p>Finally, we can assign thread to GPU with the use of language specific function. Please note that this will look differently for OpenACC and OpenMP:</p>
<ul>
  <li>OpenACC
    <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">acc_set_device_num</span><span class="p">(</span><span class="n">device_id</span><span class="p">,</span> <span class="n">acc_device_nvidia</span><span class="p">);</span>
</code></pre></div>    </div>
  </li>
  <li>OpenMP
    <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">omp_set_default_device</span><span class="p">(</span><span class="n">device_id</span><span class="p">);</span>
</code></pre></div>    </div>
  </li>
</ul>

<p>Please note that we have used new integer variables: <em>num_threads, thread_id, num_devices, device_id</em>.</p>

<p>Those need to be defined earlier in the code:</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="n">num_threads</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>				 
<span class="kt">int</span> <span class="n">thread_id</span>  <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>				 	 
<span class="kt">int</span> <span class="n">num_devices</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>				 
<span class="kt">int</span> <span class="n">device_id</span>  <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>					 
</code></pre></div></div>
<p>and also declared as <strong>firstprivate</strong> variables.</p>

<h2 id="domain-decomposition">Domain decomposition</h2>

<p>Parallelisation strategy and proper algorithm design is one the most important steps for achieving high computational performance. In the case of our Laplace example we will simply divide the problem into <em>num_threads</em> chunks (stripes) by dividing the grid in X dimension. For this we need to:</p>
<ul>
  <li>compute the size of the chunk for each thread:
    <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// calculate the chunk size based on number of threads</span>
<span class="n">chunk_size</span><span class="o">=</span><span class="n">ceil</span><span class="p">((</span><span class="mi">1</span><span class="p">.</span><span class="mi">0</span><span class="o">*</span><span class="n">GRIDX</span><span class="p">)</span><span class="o">/</span><span class="n">num_threads</span><span class="p">);</span>
</code></pre></div>    </div>
  </li>
  <li>calculate X direction loop bounds for each thread:
    <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// calculate boundaries and process only inner region</span>
<span class="n">i_start</span> <span class="o">=</span> <span class="n">thread_id</span> <span class="o">*</span> <span class="n">chunk_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
<span class="n">i_end</span>   <span class="o">=</span> <span class="n">i_start</span> <span class="o">+</span> <span class="n">chunk_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span>
</code></pre></div>    </div>
    <p>Please note that all those variable need to be defined earlier as well as declared as <strong>firstprivate</strong>.</p>
  </li>
</ul>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>					 
<span class="kt">int</span> <span class="n">i_start</span><span class="p">,</span> <span class="n">i_end</span><span class="p">;</span>					
</code></pre></div></div>

<p>We can now change both i-loops to iterate within the precomputed boundaries:</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span><span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="n">i_start</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">i_end</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
</code></pre></div></div>

<blockquote class="callout">
  <h2 id="caution">Caution</h2>
  <p>There is one very important component missing: halo-exchange. Left-hand side and right-hand side boundaries of each stripe (chunk) need to be synchronised with other threads. Please continue reading to learn how that can be achieved with OpenACC and OpenMP.</p>
</blockquote>

<h2 id="firstprivate-variables">Firstprivate variables</h2>

<p>We have set the CPU default OpenMP data type to <em>shared</em>. For this reason we need to be very careful with identifying variables that need to be treated as private of firstprivate within the OpenMP parallel region.</p>

<p>Clearly, arrays <em>T</em> and <em>T_new</em> should be treated as shared. Those arrays can be potentially very big in size and each thread will be working on a separate stripe/chunk.</p>

<p>We have also noted before that <em>num_threads, thread_id, num_devices, device_id, chunk_size, i_start</em> and <em>i_end</em> variables need to be treated as firstprivate.</p>

<p>In addition to this, variables <em>dt, iteration, i</em> and <em>j</em> need to be treated as firstprivate as well.</p>

<p>Therefore, the opening of the OpenMP parallel region should be of the following form:</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#pragma omp parallel default(shared) firstprivate(num_threads, thread_id, num_devices, device_id, i_start, i_end, chunk_size,dt,iteration,i,j)
</span></code></pre></div></div>

<h2 id="halo-exchange">Halo-exchange</h2>

<p>There is one very important component missing: halo-exchange. Left-hand side and right-hand side boundaries of each stripe (chunk) need to be synchronised with other threads. Please continue reading to learn how that can be achieved with OpenACC and OpenMP. This is related to the computational nature of the Laplace equation solver. Value for each grid node is computed as an average of its 4 neighbours.</p>

<p>It is even more complicated since GPU threads are operating on a local copy of <em>T</em> and <em>T_new</em> arrays which were transferred to the GPU memory.</p>

<blockquote class="callout">
  <h2 id="question">Question</h2>
  <p>Do we need to transfer the whole <em>T</em> and <em>T_new</em> arrays back to CPU memory to achieve the synchronisation? We have already seen that copying whole arrays back and forth is a significant overhead.</p>
</blockquote>

<p>Fortunately, both OpenMP and OpenACC provide us with <em>update</em> directives which can be used to transfer only single rows or columns of 2D arrays. Therefore, each thread will:</p>
<ul>
  <li>first copy its stripe (chunk) boundaries back to CPU memory,</li>
  <li>next copy neighbouring thread boundaries from CPU memory to GPU memory.
We will place those two events right after the main computational kernel in the code.</li>
</ul>

<p>Please note that we had to introduce an additional OpenMP barrier between those two events. We need to be sure that boundaries of neighbouring threads are already available in the CPU memory.</p>

<p>This can be implemented in the following way for OpenACC:</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// main computational kernel, average over neighbours in the grid</span>
<span class="cp">#pragma acc kernels
</span><span class="k">for</span><span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="n">i_start</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">i_end</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
    <span class="k">for</span><span class="p">(</span><span class="n">j</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;=</span> <span class="n">GRIDY</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span>
        <span class="n">T_new</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">.</span><span class="mi">25</span> <span class="o">*</span> <span class="p">(</span><span class="n">T</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">T</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span>
                                    <span class="n">T</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">T</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]);</span>

<span class="cp">#pragma acc update self(T[i_start:1][1:GRIDY],T[i_end:1][1:GRIDY])
#pragma omp barrier
#pragma acc update device(T[(i_start-1):1][1:GRIDY],T[(i_end+1):1][1:GRIDY])
</span></code></pre></div></div>
<p>Similarly, for OpenMP:</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// main computational kernel, average over neighbours in the grid</span>
<span class="cp">#pragma omp target
#pragma omp teams distribute parallel for collapse(2)
</span><span class="k">for</span><span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="n">i_start</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">i_end</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
    <span class="k">for</span><span class="p">(</span><span class="n">j</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;=</span> <span class="n">GRIDY</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span>
        <span class="n">T_new</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">.</span><span class="mi">25</span> <span class="o">*</span> <span class="p">(</span><span class="n">T</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">T</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span>
                                    <span class="n">T</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">T</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]);</span>

<span class="cp">#pragma omp target update from(T[i_start:1][1:GRIDY])
#pragma omp target update from(T[i_end:1][1:GRIDY])
#pragma omp barrier
#pragma omp target update to(T[(i_start-1):1][1:GRIDY])
#pragma omp target update to(T[(i_end+1):1][1:GRIDY])
</span></code></pre></div></div>

<h2 id="synchronisation">Synchronisation</h2>

<p>Every thread is now able to compute correct result in each iteration, however we do not have proper synchronisation for the <em>dt</em> variable which is used to determine if the iterative algorithm converged. For that reason we will create a shared <em>dt_global</em> variable to compute global largest change of temperature.</p>

<p>This can be achieved in the following way:</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// reset dt</span>
<span class="n">dt</span> <span class="o">=</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">;</span>
<span class="cp">#pragma omp single
</span><span class="n">dt_global</span> <span class="o">=</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">;</span>

<span class="cp">#pragma omp barrier
</span>
<span class="c1">// compute the largest change and copy T_new to T</span>
<span class="cm">/*
OpenACC or OpenMP loop construct
*/</span>
<span class="k">for</span><span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="n">i_start</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">i_end</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">){</span>
    <span class="k">for</span><span class="p">(</span><span class="n">j</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;=</span> <span class="n">GRIDY</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">){</span>
<span class="n">dt</span> <span class="o">=</span> <span class="n">MAX</span><span class="p">(</span> <span class="n">fabs</span><span class="p">(</span><span class="n">T_new</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">-</span><span class="n">T</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]),</span> <span class="n">dt</span><span class="p">);</span>
<span class="n">T</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">T_new</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">];</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="cp">#pragma omp critical
</span><span class="n">dt_global</span> <span class="o">=</span> <span class="n">MAX</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span><span class="n">dt_global</span><span class="p">);</span>

<span class="cp">#pragma omp barrier
</span>
<span class="n">dt</span><span class="o">=</span><span class="n">dt_global</span><span class="p">;</span>
</code></pre></div></div>
<p>Local <em>dt</em> is first set to zero. One of the OpenMP threads is also setting <em>dt_global</em> to zero, this is followed by OpenMP barrier for proper synchronisation.</p>

<p>After computing local <em>dt</em>, each thread updates <em>dt_global</em>. This needs to be done in the OpenMP critical region to make sure that each thread’s value is taken into account. Work is synchronised with the use of OpenMP barrier to make sure that contribution from all threads were calculated. Finally, each thread copies <em>dt_global</em> value to local <em>dt</em>.</p>

<h2 id="diagnostic-messages">Diagnostic messages</h2>
<p>We also make sure that diagnostic messages are printed by only a single thread (in that case by the master thread).</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// periodically print largest change</span>
<span class="cp">#pragma omp master
</span><span class="k">if</span><span class="p">((</span><span class="n">iteration</span> <span class="o">%</span> <span class="mi">100</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"Iteration %4.0d, dt %f</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">iteration</span><span class="p">,</span><span class="n">dt</span><span class="p">);</span>
</code></pre></div></div>


<blockquote class="keypoints">
  <h2>Key Points</h2>
  <ul>
    
    <li><p>We have learned how to parallelise OpenACC and OpenMP applications on multiple GPUs within the node</p>
</li>
    
    <li><p>We are now able to create codes that use all computational devices available in the node</p>
</li>
    
  </ul>
</blockquote>

</article>

<div class="row">
  <div class="col-xs-1">
    <h3 class="text-left">
      
      <a href="../06-data-management/index.html"><span class="glyphicon glyphicon-menu-left" aria-hidden="true"></span><span class="sr-only">previous episode</span></a>
      
    </h3>
  </div>
  <div class="col-xs-10">
    
  </div>
  <div class="col-xs-1">
    <h3 class="text-right">
      
      <a href="../"><span class="glyphicon glyphicon-menu-up" aria-hidden="true"></span><span class="sr-only">lesson home</span></a>
      
    </h3>
  </div>
</div>


      
      	
<footer>
  <div class="row">
    <div class="col-md-6" align="left">
      <h4>
	Copyright &copy; 2016–2020
	<a href="http://pawsey.org.au">Pawsey Supercomputing Centre</a>

      </h4>
    </div>
    <div class="col-md-6" align="right">
      <h4>

	Adapted from <a href="http://software-carpentry.org">Software Carpentry</a>
	/
	<a href="mailto:mailto:help@pawsey.org.au">Contact</a>
      </h4>
    </div>
  </div>
</footer>

      
    </div>
    
<script src="../assets/js/jquery.min.js"></script>
<script src="../assets/js/bootstrap.min.js"></script>
<script src="../assets/js/lesson.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-37305346-2', 'auto');
  ga('send', 'pageview');
</script>

  </body>
</html>
